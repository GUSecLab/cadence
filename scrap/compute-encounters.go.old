package main

import (
	"database/sql"
	"errors"
	"math"
	"runtime"
	"sort"
	"sync"
	"time"

	"marathon-sim/lens"
)

// and let's do the same for the command-line arguments
var args struct {
	datasetName     *string
	experimentName  *string
	disableOptimize *bool
}

// returns the events by distance to a given marker
func sortEventsByMarkerId(events []*model.Event, markerId model.NodeId) {
	sort.Slice(events, func(i, j int) bool {
		return events[i].DistancesToMarkers[markerId] < events[j].DistancesToMarkers[markerId]
	})
}

// TODO
//
// A `Marker` is a location.  The logic here is that the simulator will randomly choose
// some nodes to act as "markers".  Then, when we are trying to figure out who
// is near whom, rather than do O(n^2) expensive distance operation, we'll
// compute the distance of each node to the markers O(nm). Now, at a time t, we
// can quickly check whether a node X is near a node Y by examining the distance
// to the markers.  This technically makes the cost O(n^2+nm), but the constant
// should be WAY less since we don't have to do expensive pairwise distance
// calculations for far-away nodes.
//
// TODO: We could also potentially populate, for each time t, an in-memory table
// that has for each node the distance to the m markers.  That's O(nm).  Then,
// when trying to figure out who is near Alice, we can sort by the distance to
// Alice's closest marker.
type Marker struct {
	MarkerID             model.NodeId
	UnmarshalledLocation lens.Location
}

// a worker is a gothread that takes in a job, where a job is a simulation time
// (t) for which the worker should find all encounters.  This operation is
// embarrassingly parallelizable, hence our use of gothreads.
func worker(encountersChan chan *lens.Encounter, jobChan chan float64, wg *sync.WaitGroup) {
	defer wg.Done()

	for job := range jobChan {
		examineTime(encountersChan, job)
	}
}

// a helper function that does all the hard work.  It's called by worker, and
// it's the function that actually finds all encounters that happen in a fixed
// time (t).
func examineTime(encountersChan chan *lens.Encounter, t float64) {

	// TODO: don't hardcode this :(
	CONSTRAINT := 1.0

	geoDistance := GeoDistance{km: true}

	log.Infof("examining time %v", t)

	var events []*model.Event
	if res := model.DB.Find(&events, "dataset_name=? and time=?", args.datasetName, t); res.Error != nil {
		log.Warnf("cannot find events at time %v: %v", t, res.Error)
		return
	}

	// unmarshall each event's location
	for _, event := range events {
		eventLocation := new(lens.LatLongAlt)
		if err := eventLocation.Unmarshal(event.MarshalledLocation); err != nil {
			log.Warnf("cannot unmarshall location: %v", err)
			continue
		}
		event.UnmarshalledLocation = eventLocation
	}

	// if we have a decent amount of nodes, then let's do some stuff to avoid
	// O(n^2) distance comparisons
	var markers []*Marker = nil
	if !*args.disableOptimize && len(events) > 50 {
		// let's create log(n) markers; let's (arbitrarily) use the natural log
		// so that we can pretend to be real scientists.
		numMarkers := int(math.Log(float64(len(events))))
		if numMarkers < 1 {
			numMarkers = 1
		}
		markers = make([]*Marker, 0, numMarkers)

		// shuffle the events randomly
		MainCSRNG.Shuffle(len(events), func(i, j int) { events[i], events[j] = events[j], events[i] })

		// select the actual markers
		for q := 0; q < numMarkers; q++ {
			var markerLocation lens.LatLongAlt
			if err := markerLocation.Unmarshal(events[q].MarshalledLocation); err != nil {
				log.Warnf("cannot unmarshall location: %v", err)
				continue
			}
			markers = append(markers, &Marker{
				MarkerID:             events[q].Node,
				UnmarshalledLocation: &markerLocation,
			})
		}

		// next, compute the distances between each node to each marker
		minDist := -1.0
		for _, event := range events {
			event.DistancesToMarkers = make(map[model.NodeId]float64)
			event.ClosestMarker = -1
			for _, marker := range markers {
				dist, _, err := geoDistance.distance(event.UnmarshalledLocation, marker.UnmarshalledLocation, nil)
				if err != nil {
					log.Fatalf("cannot compute distance; unrecoverable error: %v", err)
				}
				event.DistancesToMarkers[marker.MarkerID] = dist
				// figure out if this is the closest marker
				if minDist < 0 || dist < minDist {
					event.ClosestMarker = marker.MarkerID
					minDist = dist
				}
			}
		}
	}

	var events2 []*model.Event = events
	for _, event1 := range events {

		// create a second slice of the events, but sort in order of the closest
		// marker to event1
		if !*args.disableOptimize {
			events2 := make([]*model.Event, len(events))
			copy(events2, events)
			sortEventsByMarkerId(events2, event1.ClosestMarker)
		}

		for _, event2 := range events2 {
			//	for _, event2 := range events {

			// one doesn't "encounter" themself
			if event1.Node == event2.Node {
				continue
			}

			// OLD: let's not double-count.  The basic logic is that if Alice
			// encounters Bob, then Bob must encounter Alice. It's assuming
			// symmetry, and thus we don't want to record _both_ encounters.
			// But I'll leave this as a TODO in case there's some weird
			// antisymmetry situation we want to consider later on.
			// ..
			// UPDATE 2022-11-06: ok, I've rethought this, and I think it makes
			// more sense to record both.  It makes DB queries WAY easier. But
			// to make things faster, we'll still do this check, but assume
			// symmetry and in the encounterRecorder function, we'll record
			// both.
			if event1.Node > event2.Node {
				continue
			}

			// if event2's distance to event1's closest marker is more than
			// CONSTRAINT+event1's distance to its closest marker, then it
			// follows that event1 and event2 aren't near, and thus we don't
			// need to compute their direct distance.  The intuition is that if
			// it costs d for event1 to get to its closest marker than it
			// shouldn't cost more than d+CONSTRAINT for event2 to get there
			if (!*args.disableOptimize) &&
				(event2.DistancesToMarkers[event1.ClosestMarker] > (float64(CONSTRAINT) + event1.DistancesToMarkers[event1.ClosestMarker])) {
				break
			}

			// compute distance
			dist, isNear, err := geoDistance.distance(event1.UnmarshalledLocation, event2.UnmarshalledLocation, CONSTRAINT)
			if err != nil {
				log.Warnf("cannot compute distance: %v", err)
				continue
			}

			// finally, let's actually do something if this is an encounter
			if isNear {
				log.Debugf("encounter between Nodes %v and %v (dist=%v) at time %v!", event1.Node, event2.Node, dist, t)
				encounter := lens.Encounter{
					ExperimentName: *args.experimentName,
					DatasetName:    *args.datasetName,
					Time:           t,
					Node1:          event1.Node,
					Node2:          event2.Node,
				}
				encountersChan <- &encounter
			}
		}
	}
}

// this function sits and waits for encounters, and then records them (in
// batches, for efficiency) into the DB.
func encounterRecorder(encountersChan chan *lens.Encounter) {
	// let's arbitrarily use a buffer of 512
	batchSize := 512

	// allocate a buffer (initially of size 0) but with capacity of `batchSize`
	encounterBuffer := make([]*lens.Encounter, 0, batchSize)

	for encounter := range encountersChan {
		encounterBuffer = append(encounterBuffer, encounter)
		// if Alice encounters Bob, also record that Bob encounters Alice
		encounterBuffer = append(encounterBuffer, &lens.Encounter{
			DatasetName:    encounter.DatasetName,
			ExperimentName: encounter.ExperimentName,
			Time:           encounter.Time,
			Node1:          encounter.Node2,
			Node2:          encounter.Node1, // swap 'em
		})
		if len(encounterBuffer) >= batchSize {
			if res := model.DB.Create(&encounterBuffer); res.Error != nil {
				log.Warnf("could not save encounters to DB: %v", res.Error)
			}
			encounterBuffer = nil
		}
	}

	// if we get here, then the channel is closed.  Let's make sure we flush any
	// unsaved encounters
	if len(encounterBuffer) > 0 {
		if res := model.DB.Create(&encounterBuffer); res.Error != nil {
			log.Warnf("could not save encounters to DB: %v", res.Error)
		}
		encounterBuffer = nil
	}
}

func computeEncounters(datasetName, experimentName string, disableOptimize bool) error {

	args.datasetName = &datasetName
	args.experimentName = &experimentName
	args.disableOptimize = &disableOptimize

	exp := lens.Experiment{
		ExperimentName:     *args.experimentName,
		DatasetName:        *args.datasetName,
		DateStarted:        sql.NullTime{Valid: true, Time: time.Now()},
		DistanceConditions: "<=10",
	}
	if err := lens.CreateExperiment(exp); err != nil {
		log.Fatalf("cannot create experiment: %v", err)
	}

	if isImported, _ := lens.IsImported(*args.datasetName); !isImported {
		return errors.New("dataset not found")
	}

	// grab all the simulation timestamps for this dataset
	log.Debug("grabbing unique times")
	var times []float64
	res := model.DB.Model(&model.Event{}).Distinct().Where("dataset_name=?", *args.datasetName).Order("time").Pluck("time", &times)
	if res.Error != nil {
		log.Fatalf("cannot get times from DB: %v", res.Error)
	}
	log.Debug("grabbed unique times")

	// create a gothread that's responsible for saving the results.  Let's
	// arbitrarily use a buffer size of 100.
	encountersChan := make(chan *lens.Encounter, 100)
	go encounterRecorder(encountersChan)

	// create workers
	jobChan := make(chan float64)
	wg := new(sync.WaitGroup)
	for i := 0; i < runtime.NumCPU(); i++ {
		wg.Add(1)
		go worker(encountersChan, jobChan, wg)
	}

	for _, t := range times {
		jobChan <- t
	}
	close(jobChan)
	wg.Wait()

	// update experiment end time in DB
	exp.DateFinished = sql.NullTime{Valid: true, Time: time.Now()}
	if res := model.DB.Save(&exp); res.Error != nil {
		log.Fatalf("cannot close experiment: %v", res.Error)
	}
	return nil
}
